program
Starting <program>. Current Token is: LPAREN_T
Using rule 1
Starting <define>. Current token = LPAREN_T Lex: (
Using rule 2
Starting <param_list>. Current token = IDENT_T Lex: a
Using rule 15
Starting <param_list>. Current token = RPAREN_T Lex: )
Using rule 16
Ending <param_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <param_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt>. Current token = IDENT_T Lex: l
Using rule 8
Ending <stmt>. Current token = NUMLIT_T. Errors = 0 Lex: 5
Starting <stmt_list>. Current token = NUMLIT_T Lex: 5
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 5
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 5
Using rule 10
error
Ending <literal>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = IF_T Lex: if
Using rule 19
Starting <stmt>. Current token = IDENT_T Lex: x
Using rule 8
Ending <stmt>. Current token = IDENT_T. Errors = 0 Lex: y
Starting <stmt>. Current token = IDENT_T Lex: y
Using rule 8
Ending <stmt>. Current token = IDENT_T. Errors = 0 Lex: n
Starting <else_part>. Current token = IDENT_T Lex: n
Using rule 17
Starting <stmt>. Current token = IDENT_T Lex: n
Using rule 8
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <else_part>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = IF_T Lex: if
Using rule 19
Starting <stmt>. Current token = IDENT_T Lex: a
Using rule 8
Ending <stmt>. Current token = IDENT_T. Errors = 0 Lex: n
Starting <stmt>. Current token = IDENT_T Lex: n
Using rule 8
Ending <stmt>. Current token = IDENT_T. Errors = 0 Lex: p
Starting <else_part>. Current token = IDENT_T Lex: p
Using rule 17
Starting <stmt>. Current token = IDENT_T Lex: p
Using rule 8
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <else_part>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = LISTOP_T Lex: cadr
Using rule 20
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = IDENT_T Lex: a
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: a
Using rule 45
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: bb
Starting <more_tokens>. Current token = IDENT_T Lex: bb
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: bb
Using rule 45
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: cc
Starting <more_tokens>. Current token = IDENT_T Lex: cc
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: cc
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = LISTOP_T Lex: cdr
Using rule 20
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = IDENT_T Lex: a
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: a
Using rule 45
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: bb
Starting <more_tokens>. Current token = IDENT_T Lex: bb
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: bb
Using rule 45
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: cc
Starting <more_tokens>. Current token = IDENT_T Lex: cc
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: cc
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = LISTOP_T Lex: cddr
Using rule 20
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = IDENT_T Lex: a
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: a
Using rule 45
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: bb
Starting <more_tokens>. Current token = IDENT_T Lex: bb
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: bb
Using rule 45
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: cc
Starting <more_tokens>. Current token = IDENT_T Lex: cc
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: cc
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <qutoed_lit>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <literal>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <action>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = CONS_T Lex: cons
Using rule 21
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = IDENT_T Lex: a
Using rule 12
Starting <any_other_token>. Current token = IDENT_T Lex: a
Using rule 45
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = LPAREN_T Lex: (
Using rule 13
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = IDENT_T Lex: x
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: x
Using rule 45
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: y
Starting <more_tokens>. Current token = IDENT_T Lex: y
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: y
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: beta
Starting <more_tokens>. Current token = IDENT_T Lex: beta
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: beta
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = AND_T Lex: and
Using rule 22
Starting <stmt_list>. Current token = NUMLIT_T Lex: 4
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 4
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 4
Using rule 10
error
Ending <literal>. Current token = NUMLIT_T. Errors = 0 Lex: 5
Ending <stmt>. Current token = NUMLIT_T. Errors = 0 Lex: 5
Starting <stmt_list>. Current token = NUMLIT_T Lex: 5
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 5
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 5
Using rule 10
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = OR_T Lex: or
Using rule 23
Starting <stmt_list>. Current token = NUMLIT_T Lex: 7
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 7
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 7
Using rule 10
error
Ending <literal>. Current token = NUMLIT_T. Errors = 0 Lex: 8
Ending <stmt>. Current token = NUMLIT_T. Errors = 0 Lex: 8
Starting <stmt_list>. Current token = NUMLIT_T Lex: 8
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 8
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 8
Using rule 10
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <define>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <more_defines>. Current token = LPAREN_T Lex: (
Using rule 3
Starting <define>. Current token = LPAREN_T Lex: (
Using rule 2
Error
Error
Error
Starting <param_list>. Current token = IDENT_T Lex: ab
Using rule 15
Starting <param_list>. Current token = RPAREN_T Lex: )
Using rule 16
Ending <param_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <param_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = NUMBERP_T Lex: number?
Using rule 25
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = IDENT_T Lex: ab
Using rule 12
Starting <any_other_token>. Current token = IDENT_T Lex: ab
Using rule 45
Ending <any_other_token>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <qutoed_lit>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <literal>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <action>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = SYMBOLP_T Lex: symbol?
Using rule 26
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = CONS_T Lex: cons
Using rule 21
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = NUMLIT_T Lex: 5678
Using rule 12
Starting <any_other_token>. Current token = NUMLIT_T Lex: 5678
Using rule 46
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = AND_T Lex: and
Using rule 22
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = LISTP_T Lex: list?
Using rule 27
Starting <stmt>. Current token = NUMLIT_T Lex: 87
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 87
Using rule 10
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = CONS_T Lex: cons
Using rule 21
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = NUMLIT_T Lex: 765
Using rule 12
Starting <any_other_token>. Current token = NUMLIT_T Lex: 765
Using rule 46
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = IDENT_T Lex: e
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: e
Using rule 45
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: n
Starting <more_tokens>. Current token = IDENT_T Lex: n
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: n
Using rule 45
Ending <any_other_token>. Current token = NUMLIT_T. Errors = 0 Lex: 6
Starting <more_tokens>. Current token = NUMLIT_T Lex: 6
Using rule 13
Starting <any_other_token>. Current token = NUMLIT_T Lex: 6
Using rule 46
Ending <any_other_token>. Current token = NUMLIT_T. Errors = 0 Lex: 5
Starting <more_tokens>. Current token = NUMLIT_T Lex: 5
Using rule 13
Starting <any_other_token>. Current token = NUMLIT_T Lex: 5
Using rule 46
Ending <any_other_token>. Current token = NUMLIT_T. Errors = 0 Lex: 4
Starting <more_tokens>. Current token = NUMLIT_T Lex: 4
Using rule 13
Starting <any_other_token>. Current token = NUMLIT_T Lex: 4
Using rule 46
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = ZEROP_T Lex: zero?
Using rule 28
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = NULLP_T Lex: null?
Using rule 29
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = IF_T Lex: if
Using rule 13
Starting <any_other_token>. Current token = IF_T Lex: if
Using rule 48
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: a
Starting <more_tokens>. Current token = IDENT_T Lex: a
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: a
Using rule 45
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: b
Starting <more_tokens>. Current token = IDENT_T Lex: b
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: b
Using rule 45
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: c
Starting <more_tokens>. Current token = IDENT_T Lex: c
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: c
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = OR_T Lex: or
Using rule 23
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = AND_T Lex: and
Using rule 22
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = CHARP_T Lex: char?
Using rule 30
Starting <stmt>. Current token = NUMLIT_T Lex: 55
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 55
Using rule 10
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = CHARP_T Lex: char?
Using rule 30
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = CHARP_T Lex: char?
Using rule 30
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = IDENT_T Lex: d
Using rule 12
Starting <any_other_token>. Current token = IDENT_T Lex: d
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = STRINGP_T Lex: string?
Using rule 31
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = IDENT_T Lex: uytrewqsdwefgrhtyj7htgrfe
Using rule 12
Starting <any_other_token>. Current token = IDENT_T Lex: uytrewqsdwefgrhtyj7htgrfe
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <define>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <more_defines>. Current token = LPAREN_T Lex: (
Using rule 3
Starting <define>. Current token = LPAREN_T Lex: (
Using rule 2
Error
Error
Error
Starting <param_list>. Current token = IDENT_T Lex: g
Using rule 15
Starting <param_list>. Current token = RPAREN_T Lex: )
Using rule 16
Ending <param_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <param_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = MINUS_T Lex: -
Using rule 33
Starting <stmt>. Current token = NUMLIT_T Lex: 55
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 55
Using rule 10
error
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = IDENT_T Lex: d
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: d
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = MINUS_T Lex: -
Using rule 33
Starting <stmt>. Current token = NUMLIT_T Lex: 55
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 55
Using rule 10
error
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = NUMLIT_T Lex: 45
Using rule 13
Starting <any_other_token>. Current token = NUMLIT_T Lex: 45
Using rule 46
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = DIV_T Lex: /
Using rule 34
Starting <stmt>. Current token = IDENT_T Lex: a
Using rule 8
Ending <stmt>. Current token = NUMLIT_T. Errors = 0 Lex: 6
Starting <stmt_list>. Current token = NUMLIT_T Lex: 6
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 6
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 6
Using rule 10
error
Ending <literal>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = MULT_T Lex: *
Using rule 35
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = IDENT_T Lex: a
Using rule 12
Starting <any_other_token>. Current token = IDENT_T Lex: a
Using rule 45
Ending <any_other_token>. Current token = NUMLIT_T. Errors = 0 Lex: 77
Ending <qutoed_lit>. Current token = NUMLIT_T. Errors = 0 Lex: 77
Ending <literal>. Current token = NUMLIT_T. Errors = 0 Lex: 77
Ending <stmt>. Current token = NUMLIT_T. Errors = 0 Lex: 77
Starting <stmt_list>. Current token = NUMLIT_T Lex: 77
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 77
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 77
Using rule 10
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = EQUALTO_T Lex: =
Using rule 36
Starting <stmt_list>. Current token = NUMLIT_T Lex: 5
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 5
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 5
Using rule 10
error
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = IDENT_T Lex: a
Using rule 12
Starting <any_other_token>. Current token = IDENT_T Lex: a
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = GT_T Lex: >
Using rule 37
Starting <stmt_list>. Current token = NUMLIT_T Lex: 6
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 6
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 6
Using rule 10
error
Ending <literal>. Current token = NUMLIT_T. Errors = 0 Lex: 5
Ending <stmt>. Current token = NUMLIT_T. Errors = 0 Lex: 5
Starting <stmt_list>. Current token = NUMLIT_T Lex: 5
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 5
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 5
Using rule 10
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = LT_T Lex: <
Using rule 38
Starting <stmt_list>. Current token = NUMLIT_T Lex: 50
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 50
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 50
Using rule 10
error
Ending <literal>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = CONS_T Lex: cons
Using rule 21
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = IDENT_T Lex: a
Using rule 12
Starting <any_other_token>. Current token = IDENT_T Lex: a
Using rule 45
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = LPAREN_T Lex: (
Using rule 13
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = IDENT_T Lex: x
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: x
Using rule 45
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: y
Starting <more_tokens>. Current token = IDENT_T Lex: y
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: y
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = IDENT_T. Errors = 0 Lex: beta
Starting <more_tokens>. Current token = IDENT_T Lex: beta
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: beta
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = GTE_T Lex: >=
Using rule 39
Starting <stmt_list>. Current token = NUMLIT_T Lex: 7654
Using rule 5
Starting <stmt>. Current token = NUMLIT_T Lex: 7654
Using rule 7
Starting <literal>. Current token = NUMLIT_T Lex: 7654
Using rule 10
error
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = IDENT_T Lex: d
Using rule 12
Starting <any_other_token>. Current token = IDENT_T Lex: d
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = LTE_T Lex: <=
Using rule 40
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = NUMLIT_T Lex: 4
Using rule 13
Starting <any_other_token>. Current token = NUMLIT_T Lex: 4
Using rule 46
Ending <any_other_token>. Current token = NUMLIT_T. Errors = 0 Lex: 3
Starting <more_tokens>. Current token = NUMLIT_T Lex: 3
Using rule 13
Starting <any_other_token>. Current token = NUMLIT_T Lex: 3
Using rule 46
Ending <any_other_token>. Current token = NUMLIT_T. Errors = 0 Lex: 2
Starting <more_tokens>. Current token = NUMLIT_T Lex: 2
Using rule 13
Starting <any_other_token>. Current token = NUMLIT_T Lex: 2
Using rule 46
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <qutoed_lit>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <literal>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = LISTOP_T Lex: car
Using rule 20
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = NUMLIT_T Lex: 5
Using rule 13
Starting <any_other_token>. Current token = NUMLIT_T Lex: 5
Using rule 46
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = IDENT_T Lex: lister
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: lister
Using rule 45
Ending <any_other_token>. Current token = NUMLIT_T. Errors = 0 Lex: 5
Starting <more_tokens>. Current token = NUMLIT_T Lex: 5
Using rule 13
Starting <any_other_token>. Current token = NUMLIT_T Lex: 5
Using rule 46
Ending <any_other_token>. Current token = NUMLIT_T. Errors = 0 Lex: 6
Starting <more_tokens>. Current token = NUMLIT_T Lex: 6
Using rule 13
Starting <any_other_token>. Current token = NUMLIT_T Lex: 6
Using rule 46
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <qutoed_lit>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <literal>. Current token = LPAREN_T. Errors = 0 Lex: (
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = DISPLAY_T Lex: display
Using rule 42
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = IDENT_T Lex: function
Using rule 41
Starting <stmt_list>. Current token = IDENT_T Lex: a
Using rule 5
Starting <stmt>. Current token = IDENT_T Lex: a
Using rule 8
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <stmt_list>. Current token = LPAREN_T Lex: (
Using rule 5
Starting <stmt>. Current token = LPAREN_T Lex: (
Using rule 9
Starting <action>. Current token = NEWLINE_T Lex: newline
Using rule 43
Ending <action>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = IDENT_T Lex: anding
Using rule 13
Starting <any_other_token>. Current token = IDENT_T Lex: anding
Using rule 45
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = NUMLIT_T Lex: 6
Using rule 13
Starting <any_other_token>. Current token = NUMLIT_T Lex: 6
Using rule 46
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = CONS_T Lex: cons
Using rule 13
Starting <any_other_token>. Current token = CONS_T Lex: cons
Using rule 47
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = IF_T Lex: if
Using rule 13
Starting <any_other_token>. Current token = IF_T Lex: if
Using rule 48
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = DISPLAY_T Lex: display
Using rule 13
Starting <any_other_token>. Current token = DISPLAY_T Lex: display
Using rule 49
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = NEWLINE_T Lex: newline
Using rule 13
Starting <any_other_token>. Current token = NEWLINE_T Lex: newline
Using rule 50
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = LISTOP_T Lex: car
Using rule 13
Starting <any_other_token>. Current token = LISTOP_T Lex: car
Using rule 51
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <more_tokens>. Current token = QUOTE_T Lex: '
Using rule 13
Starting <any_other_token>. Current token = QUOTE_T Lex: '
Using rule 72
Ending <any_other_token>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <more_tokens>. Current token = LPAREN_T Lex: (
Using rule 13
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = LISTOP_T Lex: caddr
Using rule 13
Starting <any_other_token>. Current token = LISTOP_T Lex: caddr
Using rule 51
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <more_tokens>. Current token = QUOTE_T Lex: '
Using rule 13
Starting <any_other_token>. Current token = QUOTE_T Lex: '
Using rule 72
Ending <any_other_token>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <more_tokens>. Current token = LPAREN_T Lex: (
Using rule 13
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = AND_T Lex: and
Using rule 13
Starting <any_other_token>. Current token = AND_T Lex: and
Using rule 52
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <more_tokens>. Current token = QUOTE_T Lex: '
Using rule 13
Starting <any_other_token>. Current token = QUOTE_T Lex: '
Using rule 72
Ending <any_other_token>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <more_tokens>. Current token = LPAREN_T Lex: (
Using rule 13
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = OR_T Lex: or
Using rule 13
Starting <any_other_token>. Current token = OR_T Lex: or
Using rule 53
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <more_tokens>. Current token = QUOTE_T Lex: '
Using rule 13
Starting <any_other_token>. Current token = QUOTE_T Lex: '
Using rule 72
Ending <any_other_token>. Current token = LPAREN_T. Errors = 0 Lex: (
Starting <more_tokens>. Current token = LPAREN_T Lex: (
Using rule 13
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = NOT_T Lex: not
Using rule 13
Starting <any_other_token>. Current token = NOT_T Lex: not
Using rule 54
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = DEFINE_T Lex: define
Using rule 13
Starting <any_other_token>. Current token = DEFINE_T Lex: define
Using rule 55
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = NUMBERP_T Lex: number?
Using rule 13
Starting <any_other_token>. Current token = NUMBERP_T Lex: number?
Using rule 56
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = SYMBOLP_T Lex: symbol?
Using rule 13
Starting <any_other_token>. Current token = SYMBOLP_T Lex: symbol?
Using rule 57
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = LISTP_T Lex: list?
Using rule 13
Starting <any_other_token>. Current token = LISTP_T Lex: list?
Using rule 58
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = ZEROP_T Lex: zero?
Using rule 13
Starting <any_other_token>. Current token = ZEROP_T Lex: zero?
Using rule 59
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = NULLP_T Lex: null?
Using rule 13
Starting <any_other_token>. Current token = NULLP_T Lex: null?
Using rule 60
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = CHARP_T Lex: char?
Using rule 13
Starting <any_other_token>. Current token = CHARP_T Lex: char?
Using rule 61
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = STRINGP_T Lex: string?
Using rule 13
Starting <any_other_token>. Current token = STRINGP_T Lex: string?
Using rule 62
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = PLUS_T Lex: +
Using rule 13
Starting <any_other_token>. Current token = PLUS_T Lex: +
Using rule 63
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = MINUS_T Lex: -
Using rule 13
Starting <any_other_token>. Current token = MINUS_T Lex: -
Using rule 64
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = DIV_T Lex: /
Using rule 13
Starting <any_other_token>. Current token = DIV_T Lex: /
Using rule 65
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = MULT_T Lex: *
Using rule 13
Starting <any_other_token>. Current token = MULT_T Lex: *
Using rule 66
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = EQUALTO_T Lex: =
Using rule 13
Starting <any_other_token>. Current token = EQUALTO_T Lex: =
Using rule 67
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = GT_T Lex: >
Using rule 13
Starting <any_other_token>. Current token = GT_T Lex: >
Using rule 68
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = LT_T Lex: <
Using rule 13
Starting <any_other_token>. Current token = LT_T Lex: <
Using rule 69
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = GTE_T Lex: >=
Using rule 13
Starting <any_other_token>. Current token = GTE_T Lex: >=
Using rule 70
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = LTE_T Lex: <=
Using rule 13
Starting <any_other_token>. Current token = LTE_T Lex: <=
Using rule 71
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <qutoed_lit>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <literal>. Current token = QUOTE_T. Errors = 0 Lex: '
Ending <stmt>. Current token = QUOTE_T. Errors = 0 Lex: '
Starting <stmt_list>. Current token = QUOTE_T Lex: '
Using rule 5
Starting <stmt>. Current token = QUOTE_T Lex: '
Using rule 7
Starting <literal>. Current token = QUOTE_T Lex: '
Using rule 11
Starting <quoted_lit>. Current token = LPAREN_T Lex: (
Using rule 12
Starting <any_other_token>. Current token = LPAREN_T Lex: (
Using rule 44
Starting <more_tokens>. Current token = QUOTE_T Lex: '
Using rule 13
Starting <any_other_token>. Current token = QUOTE_T Lex: '
Using rule 72
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <more_tokens>. Current token = RPAREN_T Lex: )
Using rule 14
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <more_tokens>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <any_other_token>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <qutoed_lit>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <literal>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt>. Current token = RPAREN_T. Errors = 0 Lex: )
Starting <stmt_list>. Current token = RPAREN_T Lex: )
Using rule 6
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <stmt_list>. Current token = RPAREN_T. Errors = 0 Lex: )
Ending <define>. Current token = EOF_T. Errors = 0 Lex: )
Starting <more_defines>. Current token = EOF_T Lex: )
Using rule 4
Ending <more_defines>. Current token = EOF_T. Errors = 0 Lex: )
Ending <more_defines>. Current token = EOF_T. Errors = 0 Lex: )
Ending <more_defines>. Current token = EOF_T. Errors = 0 Lex: )
Ending <program>. Current Token = EOF_T. Errors = 0 Lex: )
